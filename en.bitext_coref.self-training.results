INFO:	2014-07-23_22-28-27	ml_framework.self_training:fc65b7403a	testing several featsets
FEATS:	mono_all : all features + CharniakElsner2009 + NE + WordNet classes + is_referential(NADA_0.5)	8f801ad5b1	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003|	000	001	002	003
TRAIN:	75.80 (14605/19269)	71.46 (13769/19269)	70.07 (13502/19269)	68.90 (13277/19269)|	78.62 (15149/19269)	73.49 (14161/19269)	71.26 (13732/19269)	70.12 (13512/19269)
	76.62 (13939/18192)	71.43 (13746/19245)	70.06 (13445/19191)	68.92 (13194/19143)|	79.47 (14308/18004)	73.42 (14005/19076)	71.23 (13666/19185)	70.11 (13415/19134)
	83.19 (13939/16755)	82.04 (13746/16755)	80.24 (13445/16755)	78.75 (13194/16755)|	85.40 (14308/16755)	83.59 (14005/16755)	81.56 (13666/16755)	80.07 (13415/16755)
	79.77 	76.37 	74.81 	73.51 |	82.33 	78.17 	76.05 	74.76 
TEST:	60.29 (1198/1987)	55.76 (1108/1987)	54.20 (1077/1987)	53.25 (1058/1987)|	60.74 (1207/1987)	57.42 (1141/1987)	54.96 (1092/1987)	53.70 (1067/1987)
	59.53 (1096/1841)	55.67 (1104/1983)	53.99 (1068/1978)	53.04 (1047/1974)|	60.10 (1095/1822)	56.95 (1119/1965)	54.78 (1084/1979)	53.42 (1054/1973)
	79.48 (1096/1379)	80.06 (1104/1379)	77.45 (1068/1379)	75.92 (1047/1379)|	79.41 (1095/1379)	81.15 (1119/1379)	78.61 (1084/1379)	76.43 (1054/1379)
	68.07 	65.68 	63.63 	62.45 |	68.42 	66.93 	64.56 	62.89 
FEATS:	aligned_all : mono_all + feature from alignment	3ce2359d78	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential, align_c_sent_dist, align_c_clause_dist, align_c_file_deepord_dist, align_c_cand_ord, align_c_anaph_sentord, align_c_cand_fun, align_c_anaph_fun, align_b_fun_agree, align_c_join_fun, align_c_cand_afun, align_c_anaph_afun, align_b_afun_agree, align_c_join_afun, align_b_cand_akt, align_b_anaph_akt, align_b_akt_agree, align_b_cand_subj, align_b_anaph_subj, align_b_subj_agree, align_c_cand_gen, align_c_anaph_gen, align_b_gen_agree, align_c_join_gen, align_c_cand_num, align_c_anaph_num, align_b_num_agree, align_c_join_num, align_c_cand_apos, align_c_anaph_apos, align_c_join_apos, align_c_cand_asubpos, align_c_anaph_asubpos, align_c_join_asubpos, align_c_cand_agen, align_c_anaph_agen, align_c_join_agen, align_c_cand_anum, align_c_anaph_anum, align_c_join_anum, align_c_cand_acase, align_c_anaph_acase, align_c_join_acase, align_c_cand_apossgen, align_c_anaph_apossgen, align_c_join_apossgen, align_c_cand_apossnum, align_c_anaph_apossnum, align_c_join_apossnum, align_c_cand_apers, align_c_anaph_apers, align_c_join_apers, align_b_cand_coord, align_b_app_in_coord, align_c_cand_epar_fun, align_c_anaph_epar_fun, align_b_epar_fun_agree, align_c_join_epar_fun, align_c_cand_epar_sempos, align_c_anaph_epar_sempos, align_b_epar_sempos_agree, align_c_join_epar_sempos, align_b_epar_lemma_agree, align_c_join_epar_lemma, align_c_join_clemma_aeparlemma, align_c_cand_tfa, align_c_anaph_tfa, align_b_tfa_agree, align_c_join_tfa, align_b_sibl, align_b_coll, align_r_cnk_coll, align_r_cand_freq, align_b_cand_pers, align_cand_ewn_class
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003|	000	001	002	003
TRAIN:	77.05 (14847/19269)	72.30 (13931/19269)	70.99 (13679/19269)	69.94 (13477/19269)|	80.20 (15454/19269)	74.72 (14397/19269)	72.62 (13993/19269)	71.59 (13795/19269)
	77.79 (14169/18215)	72.25 (13890/19226)	70.99 (13601/19159)	69.99 (13368/19100)|	81.00 (14589/18010)	74.65 (14182/18999)	72.58 (13894/19144)	71.60 (13657/19075)
	84.57 (14169/16755)	82.90 (13890/16755)	81.18 (13601/16755)	79.79 (13368/16755)|	87.07 (14589/16755)	84.64 (14182/16755)	82.92 (13894/16755)	81.51 (13657/16755)
	81.04 	77.21 	75.74 	74.57 |	83.93 	79.33 	77.41 	76.23 
TEST:	60.80 (1208/1987)	56.62 (1125/1987)	55.81 (1109/1987)	54.76 (1088/1987)|	61.90 (1230/1987)	57.78 (1148/1987)	56.57 (1124/1987)	55.36 (1100/1987)
	60.13 (1110/1846)	56.53 (1121/1983)	55.55 (1096/1973)	54.55 (1073/1967)|	60.96 (1112/1824)	57.27 (1122/1959)	56.29 (1110/1972)	55.11 (1084/1967)
	80.49 (1110/1379)	81.29 (1121/1379)	79.48 (1096/1379)	77.81 (1073/1379)|	80.64 (1112/1379)	81.36 (1122/1379)	80.49 (1110/1379)	78.61 (1084/1379)
	68.84 	66.69 	65.39 	64.14 |	69.43 	67.23 	66.25 	64.79 
FEATS:	aligned_coref+mono_all : mono_all + coref from alignment	8585247ec4	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential, align_is_coref
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003|	000	001	002	003
TRAIN:	76.29 (14700/19269)	71.88 (13851/19269)	70.57 (13599/19269)	69.62 (13416/19269)|	78.83 (15190/19269)	73.92 (14244/19269)	71.91 (13856/19269)	70.86 (13654/19269)
	77.05 (13986/18152)	71.85 (13828/19246)	70.55 (13556/19214)	69.61 (13347/19173)|	79.64 (14317/17977)	73.85 (14091/19081)	71.87 (13797/19198)	70.84 (13567/19152)
	83.47 (13986/16755)	82.53 (13828/16755)	80.91 (13556/16755)	79.66 (13347/16755)|	85.45 (14317/16755)	84.10 (14091/16755)	82.35 (13797/16755)	80.97 (13567/16755)
	80.13 	76.82 	75.38 	74.30 |	82.44 	78.64 	76.75 	75.57 
TEST:	62.25 (1237/1987)	56.52 (1123/1987)	55.31 (1099/1987)	54.00 (1073/1987)|	62.25 (1237/1987)	57.88 (1150/1987)	55.71 (1107/1987)	54.55 (1084/1987)
	61.48 (1133/1843)	56.43 (1119/1983)	55.15 (1092/1980)	53.74 (1062/1976)|	61.48 (1125/1830)	57.43 (1128/1964)	55.53 (1099/1979)	54.32 (1074/1977)
	82.16 (1133/1379)	81.15 (1119/1379)	79.19 (1092/1379)	77.01 (1062/1379)|	81.58 (1125/1379)	81.80 (1128/1379)	79.70 (1099/1379)	77.88 (1074/1379)
	70.33 	66.57 	65.02 	63.31 |	70.12 	67.48 	65.46 	64.00 
FEATS:	aligned_all+coref+mono_all : mono_all + coref and all features from alignment	0bb0a1d6c9	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential, align_c_sent_dist, align_c_clause_dist, align_c_file_deepord_dist, align_c_cand_ord, align_c_anaph_sentord, align_c_cand_fun, align_c_anaph_fun, align_b_fun_agree, align_c_join_fun, align_c_cand_afun, align_c_anaph_afun, align_b_afun_agree, align_c_join_afun, align_b_cand_akt, align_b_anaph_akt, align_b_akt_agree, align_b_cand_subj, align_b_anaph_subj, align_b_subj_agree, align_c_cand_gen, align_c_anaph_gen, align_b_gen_agree, align_c_join_gen, align_c_cand_num, align_c_anaph_num, align_b_num_agree, align_c_join_num, align_c_cand_apos, align_c_anaph_apos, align_c_join_apos, align_c_cand_asubpos, align_c_anaph_asubpos, align_c_join_asubpos, align_c_cand_agen, align_c_anaph_agen, align_c_join_agen, align_c_cand_anum, align_c_anaph_anum, align_c_join_anum, align_c_cand_acase, align_c_anaph_acase, align_c_join_acase, align_c_cand_apossgen, align_c_anaph_apossgen, align_c_join_apossgen, align_c_cand_apossnum, align_c_anaph_apossnum, align_c_join_apossnum, align_c_cand_apers, align_c_anaph_apers, align_c_join_apers, align_b_cand_coord, align_b_app_in_coord, align_c_cand_epar_fun, align_c_anaph_epar_fun, align_b_epar_fun_agree, align_c_join_epar_fun, align_c_cand_epar_sempos, align_c_anaph_epar_sempos, align_b_epar_sempos_agree, align_c_join_epar_sempos, align_b_epar_lemma_agree, align_c_join_epar_lemma, align_c_join_clemma_aeparlemma, align_c_cand_tfa, align_c_anaph_tfa, align_b_tfa_agree, align_c_join_tfa, align_b_sibl, align_b_coll, align_r_cnk_coll, align_r_cand_freq, align_b_cand_pers, align_cand_ewn_class, align_is_coref
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003|	000	001	002	003
TRAIN:	77.32 (14898/19269)	72.85 (14038/19269)	71.26 (13731/19269)	70.42 (13570/19269)|	80.04 (15423/19269)	75.93 (14631/19269)	72.75 (14019/19269)	71.70 (13815/19269)
	78.00 (14179/18179)	72.80 (13988/19214)	71.21 (13655/19176)	70.39 (13473/19141)|	80.75 (14529/17993)	76.09 (14170/18623)	72.70 (13922/19151)	71.65 (13690/19106)
	84.63 (14179/16755)	83.49 (13988/16755)	81.50 (13655/16755)	80.41 (13473/16755)|	86.71 (14529/16755)	84.57 (14170/16755)	83.09 (13922/16755)	81.71 (13690/16755)
	81.18 	77.78 	76.01 	75.07 |	83.62 	80.11 	77.55 	76.35 
TEST:	62.10 (1234/1987)	56.87 (1130/1987)	55.66 (1106/1987)	54.60 (1085/1987)|	62.61 (1244/1987)	59.99 (1192/1987)	56.32 (1119/1987)	55.26 (1098/1987)
	61.19 (1129/1845)	56.74 (1124/1981)	55.46 (1097/1978)	54.40 (1075/1976)|	61.71 (1130/1831)	59.27 (1119/1888)	56.07 (1108/1976)	54.97 (1084/1972)
	81.87 (1129/1379)	81.51 (1124/1379)	79.55 (1097/1379)	77.96 (1075/1379)|	81.94 (1130/1379)	81.15 (1119/1379)	80.35 (1108/1379)	78.61 (1084/1379)
	70.04 	66.90 	65.36 	64.08 |	70.40 	68.50 	66.05 	64.70 
INFO:	2014-07-23_23-41-59	ml_framework.self_training:2079da414b	feats=mono_all self-training delible=1 min_loss=1
FEATS:	mono_all : all features + CharniakElsner2009 + NE + WordNet classes + is_referential(NADA_0.5)	8f801ad5b1	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010|	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	75.80 (14605/19269)	73.42 (14147/19269)	71.77 (13829/19269)	69.98 (13485/19269)	67.53 (13013/19269)	65.90 (12698/19269)	64.44 (12416/19269)	63.01 (12141/19269)	61.66 (11881/19269)	60.30 (11620/19269)	59.25 (11417/19269)|	78.62 (15149/19269)	75.82 (14610/19269)	73.45 (14154/19269)	71.61 (13798/19269)	69.44 (13380/19269)	67.39 (12986/19269)	65.94 (12706/19269)	64.51 (12430/19269)	63.14 (12167/19269)	61.83 (11914/19269)	60.74 (11704/19269)
	76.62 (13939/18192)	74.50 (13541/18175)	72.50 (13285/18324)	70.40 (13066/18559)	67.52 (12924/19141)	65.87 (12674/19242)	64.40 (12389/19239)	62.97 (12114/19238)	61.62 (11854/19238)	60.26 (11594/19239)	59.22 (11392/19237)|	79.47 (14308/18004)	76.75 (13862/18061)	74.31 (13515/18187)	72.15 (13290/18421)	69.38 (13181/18999)	67.36 (12960/19240)	65.90 (12678/19238)	64.47 (12401/19236)	63.10 (12140/19238)	61.79 (11888/19239)	60.70 (11677/19238)
	83.19 (13939/16755)	80.82 (13541/16755)	79.29 (13285/16755)	77.98 (13066/16755)	77.14 (12924/16755)	75.64 (12674/16755)	73.94 (12389/16755)	72.30 (12114/16755)	70.75 (11854/16755)	69.20 (11594/16755)	67.99 (11392/16755)|	85.40 (14308/16755)	82.73 (13862/16755)	80.66 (13515/16755)	79.32 (13290/16755)	78.67 (13181/16755)	77.35 (12960/16755)	75.67 (12678/16755)	74.01 (12401/16755)	72.46 (12140/16755)	70.95 (11888/16755)	69.69 (11677/16755)
	79.77 	77.53 	75.74 	74.00 	72.01 	70.42 	68.84 	67.31 	65.87 	64.42 	63.30 |	82.33 	79.63 	77.36 	75.56 	73.73 	72.01 	70.45 	68.91 	67.46 	66.06 	64.88 
TEST:	60.29 (1198/1987)	59.18 (1176/1987)	57.37 (1140/1987)	55.41 (1101/1987)	52.54 (1044/1987)	51.13 (1016/1987)	50.08 (995/1987)	49.42 (982/1987)	48.16 (957/1987)	47.51 (944/1987)	46.85 (931/1987)|	60.74 (1207/1987)	60.49 (1202/1987)	58.88 (1170/1987)	56.27 (1118/1987)	53.70 (1067/1987)	51.69 (1027/1987)	50.83 (1010/1987)	50.33 (1000/1987)	48.82 (970/1987)	48.06 (955/1987)	47.26 (939/1987)
	59.53 (1096/1841)	58.69 (1081/1842)	57.07 (1065/1866)	55.25 (1048/1897)	52.28 (1032/1974)	51.03 (1012/1983)	49.97 (991/1983)	49.32 (978/1983)	48.06 (953/1983)	47.40 (940/1983)	46.75 (927/1983)|	60.10 (1095/1822)	59.87 (1095/1829)	58.44 (1080/1848)	56.09 (1054/1879)	53.27 (1044/1960)	51.56 (1022/1982)	50.71 (1005/1982)	50.20 (995/1982)	48.71 (966/1983)	47.96 (951/1983)	47.15 (935/1983)
	79.48 (1096/1379)	78.39 (1081/1379)	77.23 (1065/1379)	76.00 (1048/1379)	74.84 (1032/1379)	73.39 (1012/1379)	71.86 (991/1379)	70.92 (978/1379)	69.11 (953/1379)	68.17 (940/1379)	67.22 (927/1379)|	79.41 (1095/1379)	79.41 (1095/1379)	78.32 (1080/1379)	76.43 (1054/1379)	75.71 (1044/1379)	74.11 (1022/1379)	72.88 (1005/1379)	72.15 (995/1379)	70.05 (966/1379)	68.96 (951/1379)	67.80 (935/1379)
	68.07 	67.12 	65.64 	63.98 	61.56 	60.20 	58.95 	58.18 	56.69 	55.92 	55.15 |	68.42 	68.27 	66.94 	64.70 	62.53 	60.82 	59.80 	59.21 	57.47 	56.57 	55.62 
INFO:	2014-07-23_23-42-33	ml_framework.self_training:2079da414b	feats=mono_all self-training delible=1 min_loss=0
FEATS:	mono_all : all features + CharniakElsner2009 + NE + WordNet classes + is_referential(NADA_0.5)	8f801ad5b1	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010|	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	75.80 (14605/19269)	71.46 (13769/19269)	70.07 (13502/19269)	68.90 (13277/19269)	67.70 (13045/19269)	66.29 (12773/19269)	64.95 (12516/19269)	63.61 (12257/19269)	62.06 (11958/19269)	60.55 (11668/19269)	58.88 (11345/19269)|	78.62 (15149/19269)	73.49 (14161/19269)	71.26 (13732/19269)	70.12 (13512/19269)	68.92 (13280/19269)	67.63 (13031/19269)	66.17 (12750/19269)	64.86 (12497/19269)	63.34 (12205/19269)	61.83 (11914/19269)	60.18 (11596/19269)
	76.62 (13939/18192)	71.43 (13746/19245)	70.06 (13445/19191)	68.92 (13194/19143)	67.72 (12957/19134)	66.28 (12686/19140)	64.95 (12436/19148)	63.60 (12185/19160)	62.05 (11897/19174)	60.52 (11608/19182)	58.84 (11290/19189)|	79.47 (14308/18004)	73.42 (14005/19076)	71.23 (13666/19185)	70.11 (13415/19134)	68.92 (13176/19117)	67.63 (12930/19119)	66.14 (12649/19125)	64.83 (12413/19148)	63.30 (12131/19163)	61.80 (11851/19177)	60.14 (11533/19178)
	83.19 (13939/16755)	82.04 (13746/16755)	80.24 (13445/16755)	78.75 (13194/16755)	77.33 (12957/16755)	75.71 (12686/16755)	74.22 (12436/16755)	72.72 (12185/16755)	71.01 (11897/16755)	69.28 (11608/16755)	67.38 (11290/16755)|	85.40 (14308/16755)	83.59 (14005/16755)	81.56 (13666/16755)	80.07 (13415/16755)	78.64 (13176/16755)	77.17 (12930/16755)	75.49 (12649/16755)	74.09 (12413/16755)	72.40 (12131/16755)	70.73 (11851/16755)	68.83 (11533/16755)
	79.77 	76.37 	74.81 	73.51 	72.21 	70.68 	69.28 	67.85 	66.23 	64.60 	62.82 |	82.33 	78.17 	76.05 	74.76 	73.46 	72.09 	70.51 	69.15 	67.55 	65.96 	64.19 
TEST:	60.29 (1198/1987)	55.76 (1108/1987)	54.20 (1077/1987)	53.25 (1058/1987)	52.39 (1041/1987)	51.94 (1032/1987)	51.38 (1021/1987)	50.63 (1006/1987)	49.32 (980/1987)	47.81 (950/1987)	46.65 (927/1987)|	60.74 (1207/1987)	57.42 (1141/1987)	54.96 (1092/1987)	53.70 (1067/1987)	52.59 (1045/1987)	51.99 (1033/1987)	51.69 (1027/1987)	50.88 (1011/1987)	49.72 (988/1987)	48.21 (958/1987)	47.01 (934/1987)
	59.53 (1096/1841)	55.67 (1104/1983)	53.99 (1068/1978)	53.04 (1047/1974)	52.23 (1029/1970)	51.78 (1020/1970)	51.19 (1010/1973)	50.43 (996/1975)	49.19 (974/1980)	47.68 (945/1982)	46.52 (922/1982)|	60.10 (1095/1822)	56.95 (1119/1965)	54.78 (1084/1979)	53.42 (1054/1973)	52.36 (1031/1969)	51.78 (1020/1970)	51.47 (1015/1972)	50.66 (1000/1974)	49.57 (981/1979)	48.08 (952/1980)	46.87 (929/1982)
	79.48 (1096/1379)	80.06 (1104/1379)	77.45 (1068/1379)	75.92 (1047/1379)	74.62 (1029/1379)	73.97 (1020/1379)	73.24 (1010/1379)	72.23 (996/1379)	70.63 (974/1379)	68.53 (945/1379)	66.86 (922/1379)|	79.41 (1095/1379)	81.15 (1119/1379)	78.61 (1084/1379)	76.43 (1054/1379)	74.76 (1031/1379)	73.97 (1020/1379)	73.60 (1015/1379)	72.52 (1000/1379)	71.14 (981/1379)	69.04 (952/1379)	67.37 (929/1379)
	68.07 	65.68 	63.63 	62.45 	61.45 	60.91 	60.26 	59.39 	57.99 	56.23 	54.86 |	68.42 	66.93 	64.56 	62.89 	61.59 	60.91 	60.58 	59.65 	58.43 	56.68 	55.28 
INFO:	2014-07-23_23-42-48	ml_framework.self_training:2079da414b	feats=mono_all self-training delible=1 min_loss=-1
FEATS:	mono_all : all features + CharniakElsner2009 + NE + WordNet classes + is_referential(NADA_0.5)	8f801ad5b1	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010|	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	75.80 (14605/19269)	71.36 (13751/19269)	69.87 (13464/19269)	68.29 (13158/19269)	66.73 (12858/19269)	65.25 (12573/19269)	64.07 (12345/19269)	62.69 (12079/19269)	60.95 (11745/19269)	59.24 (11415/19269)	57.51 (11082/19269)|	78.62 (15149/19269)	72.90 (14048/19269)	71.34 (13746/19269)	69.68 (13426/19269)	68.01 (13104/19269)	66.58 (12830/19269)	65.33 (12589/19269)	64.12 (12355/19269)	62.50 (12044/19269)	60.80 (11715/19269)	59.16 (11400/19269)
	76.62 (13939/18192)	71.37 (13624/19088)	70.34 (13139/18679)	69.01 (12780/18519)	67.62 (12471/18444)	66.10 (12197/18452)	64.74 (12006/18546)	63.24 (11780/18627)	61.35 (11502/18748)	59.54 (11220/18843)	57.68 (10920/18932)|	79.47 (14308/18004)	72.88 (13909/19085)	71.75 (13370/18634)	70.42 (12979/18430)	68.98 (12651/18340)	67.49 (12377/18339)	66.16 (12169/18393)	64.72 (11981/18512)	62.98 (11711/18596)	61.21 (11456/18717)	59.42 (11194/18840)
	83.19 (13939/16755)	81.31 (13624/16755)	78.42 (13139/16755)	76.28 (12780/16755)	74.43 (12471/16755)	72.80 (12197/16755)	71.66 (12006/16755)	70.31 (11780/16755)	68.65 (11502/16755)	66.97 (11220/16755)	65.17 (10920/16755)|	85.40 (14308/16755)	83.01 (13909/16755)	79.80 (13370/16755)	77.46 (12979/16755)	75.51 (12651/16755)	73.87 (12377/16755)	72.63 (12169/16755)	71.51 (11981/16755)	69.90 (11711/16755)	68.37 (11456/16755)	66.81 (11194/16755)
	79.77 	76.02 	74.16 	72.46 	70.86 	69.29 	68.02 	66.59 	64.79 	63.04 	61.20 |	82.33 	77.62 	75.56 	73.78 	72.10 	70.54 	69.24 	67.94 	66.26 	64.59 	62.90 
TEST:	60.29 (1198/1987)	55.61 (1105/1987)	54.55 (1084/1987)	53.55 (1064/1987)	53.04 (1054/1987)	52.39 (1041/1987)	50.83 (1010/1987)	49.62 (986/1987)	48.47 (963/1987)	46.85 (931/1987)	45.50 (904/1987)|	60.74 (1207/1987)	56.17 (1116/1987)	55.81 (1109/1987)	54.30 (1079/1987)	53.65 (1066/1987)	52.39 (1041/1987)	51.43 (1022/1987)	50.38 (1001/1987)	49.12 (976/1987)	47.86 (951/1987)	46.25 (919/1987)
	59.53 (1096/1841)	55.28 (1089/1970)	54.56 (1046/1917)	53.64 (1017/1896)	52.99 (1002/1891)	52.43 (992/1892)	50.81 (967/1903)	49.53 (951/1920)	48.27 (933/1933)	46.70 (906/1940)	45.41 (885/1949)|	60.10 (1095/1822)	55.76 (1098/1969)	55.57 (1057/1902)	54.17 (1020/1883)	53.64 (1009/1881)	52.47 (988/1883)	51.51 (972/1887)	50.18 (954/1901)	48.98 (938/1915)	47.74 (919/1925)	46.13 (895/1940)
	79.48 (1096/1379)	78.97 (1089/1379)	75.85 (1046/1379)	73.75 (1017/1379)	72.66 (1002/1379)	71.94 (992/1379)	70.12 (967/1379)	68.96 (951/1379)	67.66 (933/1379)	65.70 (906/1379)	64.18 (885/1379)|	79.41 (1095/1379)	79.62 (1098/1379)	76.65 (1057/1379)	73.97 (1020/1379)	73.17 (1009/1379)	71.65 (988/1379)	70.49 (972/1379)	69.18 (954/1379)	68.02 (938/1379)	66.64 (919/1379)	64.90 (895/1379)
	68.07 	65.03 	63.47 	62.11 	61.28 	60.65 	58.93 	57.65 	56.34 	54.59 	53.19 |	68.42 	65.59 	64.43 	62.54 	61.90 	60.58 	59.52 	58.17 	56.95 	55.63 	53.93 
INFO:	2014-07-23_23-42-59	ml_framework.self_training:2079da414b	feats=mono_all self-training delible=1 min_loss=-2
FEATS:	mono_all : all features + CharniakElsner2009 + NE + WordNet classes + is_referential(NADA_0.5)	8f801ad5b1	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010|	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	75.80 (14605/19269)	71.01 (13683/19269)	67.27 (12962/19269)	64.48 (12424/19269)	63.08 (12154/19269)	61.86 (11919/19269)	60.51 (11660/19269)	58.67 (11305/19269)	56.80 (10945/19269)	54.73 (10546/19269)	49.26 (9491/19269)|	78.62 (15149/19269)	73.20 (14105/19269)	69.13 (13320/19269)	66.17 (12750/19269)	64.61 (12449/19269)	63.48 (12232/19269)	62.31 (12007/19269)	60.44 (11647/19269)	58.56 (11283/19269)	56.61 (10908/19269)	52.64 (10144/19269)
	76.62 (13939/18192)	72.12 (13192/18293)	71.12 (12215/17174)	69.11 (11638/16840)	67.19 (11402/16969)	65.19 (11247/17252)	62.69 (11086/17685)	59.87 (10882/18176)	57.33 (10651/18579)	54.87 (10370/18898)	49.24 (9413/19117)|	79.47 (14308/18004)	73.90 (13596/18399)	72.79 (12501/17173)	70.65 (11908/16855)	68.77 (11633/16916)	66.88 (11469/17148)	64.67 (11353/17555)	61.90 (11114/17954)	59.15 (10900/18427)	56.78 (10666/18784)	52.59 (10000/19015)
	83.19 (13939/16755)	78.73 (13192/16755)	72.90 (12215/16755)	69.46 (11638/16755)	68.05 (11402/16755)	67.13 (11247/16755)	66.17 (11086/16755)	64.95 (10882/16755)	63.57 (10651/16755)	61.89 (10370/16755)	56.18 (9413/16755)|	85.40 (14308/16755)	81.15 (13596/16755)	74.61 (12501/16755)	71.07 (11908/16755)	69.43 (11633/16755)	68.45 (11469/16755)	67.76 (11353/16755)	66.33 (11114/16755)	65.06 (10900/16755)	63.66 (10666/16755)	59.68 (10000/16755)
	79.77 	75.28 	72.00 	69.28 	67.62 	66.15 	64.38 	62.31 	60.29 	58.17 	52.48 |	82.33 	77.35 	73.69 	70.86 	69.10 	67.66 	66.18 	64.04 	61.96 	60.02 	55.91 
TEST:	60.29 (1198/1987)	56.37 (1120/1987)	54.60 (1085/1987)	52.64 (1046/1987)	50.83 (1010/1987)	49.87 (991/1987)	49.27 (979/1987)	47.56 (945/1987)	45.70 (908/1987)	43.43 (863/1987)	38.60 (767/1987)|	60.74 (1207/1987)	57.37 (1140/1987)	55.56 (1104/1987)	53.20 (1057/1987)	51.74 (1028/1987)	50.33 (1000/1987)	49.67 (987/1987)	47.96 (953/1987)	46.25 (919/1987)	44.39 (882/1987)	40.97 (814/1987)
	59.53 (1096/1841)	56.38 (1051/1864)	55.86 (977/1749)	54.24 (927/1709)	52.31 (904/1728)	50.74 (897/1768)	49.45 (896/1812)	47.41 (887/1871)	45.35 (867/1912)	43.01 (837/1946)	38.29 (755/1972)|	60.10 (1095/1822)	57.25 (1070/1869)	56.65 (988/1744)	54.79 (932/1701)	53.05 (912/1719)	51.26 (894/1744)	49.97 (898/1797)	47.95 (888/1852)	46.09 (873/1894)	43.96 (852/1938)	40.63 (796/1959)
	79.48 (1096/1379)	76.21 (1051/1379)	70.85 (977/1379)	67.22 (927/1379)	65.55 (904/1379)	65.05 (897/1379)	64.97 (896/1379)	64.32 (887/1379)	62.87 (867/1379)	60.70 (837/1379)	54.75 (755/1379)|	79.41 (1095/1379)	77.59 (1070/1379)	71.65 (988/1379)	67.59 (932/1379)	66.13 (912/1379)	64.83 (894/1379)	65.12 (898/1379)	64.39 (888/1379)	63.31 (873/1379)	61.78 (852/1379)	57.72 (796/1379)
	68.07 	64.82 	62.47 	60.04 	58.19 	57.01 	56.16 	54.58 	52.69 	50.35 	45.06 |	68.42 	65.89 	63.27 	60.52 	58.88 	57.25 	56.55 	54.97 	53.35 	51.37 	47.69 
INFO:	2014-07-23_23-43-08	ml_framework.self_training:2079da414b	feats=mono_all self-training delible=1 min_loss=-3
FEATS:	mono_all : all features + CharniakElsner2009 + NE + WordNet classes + is_referential(NADA_0.5)	8f801ad5b1	__SELF__, c_sent_dist, c_clause_dist, c_file_deepord_dist, c_cand_ord, c_anaph_sentord, c_cand_fmm, c_anaph_fmm, b_fmm_agree, c_join_fmm, c_cand_fun, c_anaph_fun, b_fun_agree, c_join_fun, c_cand_afun, c_anaph_afun, b_afun_agree, c_join_afun, b_cand_akt, b_anaph_akt, b_akt_agree, b_cand_subj, b_anaph_subj, b_subj_agree, c_cand_gen, c_anaph_gen, b_gen_agree, c_join_gen, c_cand_num, c_anaph_num, b_num_agree, c_join_num, c_cand_atag, c_anaph_atag, b_atag_agree, c_join_atag, c_cand_apos, c_anaph_apos, b_apos_agree, c_join_apos, c_cand_anum, c_anaph_anum, b_anum_agree, c_join_anum, b_cand_coord, b_app_in_coord, c_cand_epar_fun, c_anaph_epar_fun, b_epar_fun_agree, c_join_epar_fun, c_cand_epar_fmm, c_anaph_epar_fmm, b_epar_fmm_agree, c_join_epar_fmm, c_cand_epar_sempos, c_anaph_epar_sempos, b_epar_sempos_agree, c_join_epar_sempos, b_epar_lemma_agree, c_join_epar_lemma, c_join_clemma_aeparlemma, b_sibl, b_coll, r_cand_freq, b_cand_pers, c_cand_loc_buck, c_anaph_loc_buck, c_cand_type, c_anaph_type, c_cand_synttype, c_cand_ne_cat, c_cand_ne_subcat, cand_ewn_class, b_anaph_referential
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 10|	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010|	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	75.80 (14605/19269)	68.59 (13217/19269)	64.79 (12484/19269)	62.84 (12108/19269)	59.96 (11553/19269)	57.68 (11115/19269)	53.87 (10380/19269)	45.25 (8720/19269)	36.79 (7090/19269)	30.82 (5938/19269)	27.11 (5224/19269)|	78.62 (15149/19269)	70.25 (13537/19269)	66.34 (12783/19269)	63.05 (12150/19269)	60.56 (11670/19269)	58.54 (11280/19269)	53.65 (10338/19269)	44.82 (8636/19269)	36.10 (6957/19269)	30.34 (5847/19269)	27.04 (5210/19269)
	76.62 (13939/18192)	74.68 (12234/16382)	72.61 (11455/15775)	69.35 (11150/16077)	65.46 (10658/16282)	60.76 (10412/17135)	55.13 (9842/17852)	45.34 (8390/18503)	36.58 (6881/18813)	30.62 (5828/19032)	27.02 (5188/19198)|	79.47 (14308/18004)	76.59 (12439/16242)	74.66 (11620/15564)	71.30 (11030/15470)	65.94 (10716/16251)	61.31 (10515/17151)	54.53 (9778/17932)	44.75 (8272/18483)	35.74 (6723/18810)	30.07 (5733/19063)	26.94 (5175/19210)
	83.19 (13939/16755)	73.02 (12234/16755)	68.37 (11455/16755)	66.55 (11150/16755)	63.61 (10658/16755)	62.14 (10412/16755)	58.74 (9842/16755)	50.07 (8390/16755)	41.07 (6881/16755)	34.78 (5828/16755)	30.96 (5188/16755)|	85.40 (14308/16755)	74.24 (12439/16755)	69.35 (11620/16755)	65.83 (11030/16755)	63.96 (10716/16755)	62.76 (10515/16755)	58.36 (9778/16755)	49.37 (8272/16755)	40.13 (6723/16755)	34.22 (5733/16755)	30.89 (5175/16755)
	79.77 	73.84 	70.43 	67.92 	64.52 	61.45 	56.88 	47.59 	38.69 	32.57 	28.86 |	82.33 	75.39 	71.91 	68.46 	64.93 	62.02 	56.38 	46.95 	37.81 	32.01 	28.78 
TEST:	60.29 (1198/1987)	56.47 (1122/1987)	53.95 (1072/1987)	51.94 (1032/1987)	50.13 (996/1987)	48.16 (957/1987)	43.94 (873/1987)	36.69 (729/1987)	30.55 (607/1987)	25.57 (508/1987)	22.85 (454/1987)|	60.74 (1207/1987)	57.37 (1140/1987)	55.86 (1110/1987)	52.44 (1042/1987)	49.92 (992/1987)	47.66 (947/1987)	42.83 (851/1987)	36.08 (717/1987)	29.84 (593/1987)	24.81 (493/1987)	22.40 (445/1987)
	59.53 (1096/1841)	58.73 (975/1660)	56.78 (904/1592)	53.66 (880/1640)	51.01 (855/1676)	47.67 (839/1760)	43.14 (795/1843)	35.72 (678/1898)	29.91 (577/1929)	25.30 (498/1968)	22.72 (450/1981)|	60.10 (1095/1822)	59.78 (978/1636)	58.86 (920/1563)	54.78 (860/1570)	50.87 (846/1663)	47.46 (831/1751)	41.84 (772/1845)	34.88 (660/1892)	29.02 (561/1933)	24.58 (483/1965)	22.25 (441/1982)
	79.48 (1096/1379)	70.70 (975/1379)	65.55 (904/1379)	63.81 (880/1379)	62.00 (855/1379)	60.84 (839/1379)	57.65 (795/1379)	49.17 (678/1379)	41.84 (577/1379)	36.11 (498/1379)	32.63 (450/1379)|	79.41 (1095/1379)	70.92 (978/1379)	66.72 (920/1379)	62.36 (860/1379)	61.35 (846/1379)	60.26 (831/1379)	55.98 (772/1379)	47.86 (660/1379)	40.68 (561/1379)	35.03 (483/1379)	31.98 (441/1379)
	68.07 	64.17 	60.85 	58.30 	55.97 	53.46 	49.35 	41.38 	34.89 	29.76 	26.79 |	68.42 	64.88 	62.54 	58.32 	55.62 	53.10 	47.89 	40.35 	33.88 	28.89 	26.24 
INFO:	2014-08-14_18-02-45	ml_framework.self_training:8a6b7bae81	self-training delible=1 diff_loss=0
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	78.62 (15150/19269)	76.00 (14645/19269)	73.66 (14194/19269)	71.37 (13752/19269)	68.91 (13278/19269)	65.84 (12686/19269)	62.21 (11987/19269)	58.96 (11361/19269)	55.64 (10722/19269)	52.66 (10148/19269)	50.33 (9698/19269)
	79.48 (14309/18004)	78.31 (13700/17494)	77.28 (13153/17019)	76.71 (12608/16435)	76.02 (12058/15861)	75.18 (11395/15157)	74.41 (10612/14262)	73.66 (9907/13450)	73.32 (9173/12511)	72.71 (8530/11732)	72.57 (8008/11035)
	85.40 (14309/16755)	81.77 (13700/16755)	78.50 (13153/16755)	75.25 (12608/16755)	71.97 (12058/16755)	68.01 (11395/16755)	63.34 (10612/16755)	59.13 (9907/16755)	54.75 (9173/16755)	50.91 (8530/16755)	47.79 (8008/16755)
	82.33 	80.00 	77.89 	75.97 	73.94 	71.42 	68.43 	65.60 	62.69 	59.89 	57.63 
TEST:	60.80 (1208/1987)	61.20 (1216/1987)	60.39 (1200/1987)	58.83 (1169/1987)	57.78 (1148/1987)	57.07 (1134/1987)	55.51 (1103/1987)	53.45 (1062/1987)	51.94 (1032/1987)	50.63 (1006/1987)	50.18 (997/1987)
	60.15 (1096/1822)	61.11 (1086/1777)	60.80 (1044/1717)	60.40 (990/1639)	59.89 (945/1578)	60.35 (895/1483)	60.01 (839/1398)	59.42 (779/1311)	58.98 (726/1231)	58.54 (682/1165)	58.95 (652/1106)
	79.48 (1096/1379)	78.75 (1086/1379)	75.71 (1044/1379)	71.79 (990/1379)	68.53 (945/1379)	64.90 (895/1379)	60.84 (839/1379)	56.49 (779/1379)	52.65 (726/1379)	49.46 (682/1379)	47.28 (652/1379)
	68.48 	68.82 	67.44 	65.61 	63.92 	62.54 	60.42 	57.92 	55.63 	53.62 	52.47 
INFO:	2014-08-14_18-02-55	ml_framework.self_training:8a6b7bae81	self-training delible=1 diff_loss=-1
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	78.62 (15150/19269)	74.45 (14345/19269)	71.81 (13838/19269)	67.76 (13057/19269)	62.83 (12107/19269)	58.06 (11187/19269)	53.68 (10344/19269)	50.21 (9675/19269)	47.02 (9060/19269)	43.79 (8438/19269)	40.10 (7727/19269)
	79.48 (14309/18004)	77.59 (13370/17231)	77.62 (12679/16335)	77.04 (11738/15237)	76.63 (10669/13922)	76.16 (9618/12629)	75.86 (8653/11406)	76.32 (7881/10326)	77.06 (7185/9324)	78.28 (6445/8233)	79.13 (5633/7119)
	85.40 (14309/16755)	79.80 (13370/16755)	75.67 (12679/16755)	70.06 (11738/16755)	63.68 (10669/16755)	57.40 (9618/16755)	51.64 (8653/16755)	47.04 (7881/16755)	42.88 (7185/16755)	38.47 (6445/16755)	33.62 (5633/16755)
	82.33 	78.68 	76.63 	73.38 	69.56 	65.46 	61.45 	58.20 	55.10 	51.58 	47.19 
TEST:	60.80 (1208/1987)	60.54 (1203/1987)	59.18 (1176/1987)	57.88 (1150/1987)	55.66 (1106/1987)	53.80 (1069/1987)	51.53 (1024/1987)	50.53 (1004/1987)	49.07 (975/1987)	47.91 (952/1987)	46.15 (917/1987)
	60.15 (1096/1822)	60.91 (1058/1737)	61.05 (989/1620)	61.20 (918/1500)	61.44 (827/1346)	61.56 (759/1233)	61.28 (690/1126)	62.33 (632/1014)	63.04 (580/920)	64.68 (522/807)	66.37 (450/678)
	79.48 (1096/1379)	76.72 (1058/1379)	71.72 (989/1379)	66.57 (918/1379)	59.97 (827/1379)	55.04 (759/1379)	50.04 (690/1379)	45.83 (632/1379)	42.06 (580/1379)	37.85 (522/1379)	32.63 (450/1379)
	68.48 	67.91 	65.96 	63.77 	60.70 	58.12 	55.09 	52.82 	50.46 	47.76 	43.75 
INFO:	2014-08-14_18-03-05	ml_framework.self_training:8a6b7bae81	self-training delible=1 diff_loss=-2
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	78.62 (15150/19269)	72.65 (13998/19269)	68.79 (13255/19269)	61.73 (11894/19269)	55.58 (10710/19269)	50.37 (9706/19269)	45.60 (8786/19269)	38.20 (7361/19269)	32.10 (6185/19269)	29.17 (5620/19269)	27.54 (5306/19269)
	79.48 (14309/18004)	77.92 (12881/16531)	78.64 (11892/15123)	78.62 (10325/13132)	79.34 (8954/11286)	80.47 (7804/9698)	82.21 (6739/8197)	82.30 (5181/6295)	81.21 (3919/4826)	80.92 (3317/4099)	81.08 (2978/3673)
	85.40 (14309/16755)	76.88 (12881/16755)	70.98 (11892/16755)	61.62 (10325/16755)	53.44 (8954/16755)	46.58 (7804/16755)	40.22 (6739/16755)	30.92 (5181/16755)	23.39 (3919/16755)	19.80 (3317/16755)	17.77 (2978/16755)
	82.33 	77.40 	74.61 	69.09 	63.86 	59.00 	54.02 	44.95 	36.32 	31.81 	29.16 
TEST:	60.80 (1208/1987)	59.84 (1189/1987)	58.28 (1158/1987)	54.91 (1091/1987)	53.55 (1064/1987)	51.43 (1022/1987)	49.87 (991/1987)	45.29 (900/1987)	41.07 (816/1987)	39.56 (786/1987)	38.25 (760/1987)
	60.15 (1096/1822)	61.29 (1023/1669)	62.47 (922/1476)	62.64 (793/1266)	64.60 (710/1099)	66.28 (623/940)	69.11 (537/777)	69.00 (414/600)	67.67 (314/464)	67.68 (266/393)	66.57 (235/353)
	79.48 (1096/1379)	74.18 (1023/1379)	66.86 (922/1379)	57.51 (793/1379)	51.49 (710/1379)	45.18 (623/1379)	38.94 (537/1379)	30.02 (414/1379)	22.77 (314/1379)	19.29 (266/1379)	17.04 (235/1379)
	68.48 	67.13 	64.59 	59.96 	57.30 	53.73 	49.81 	41.84 	34.07 	30.02 	27.14 
INFO:	2014-08-14_18-03-15	ml_framework.self_training:8a6b7bae81	self-training delible=1 diff_loss=-3
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	78.62 (15150/19269)	70.92 (13666/19269)	64.56 (12441/19269)	55.64 (10721/19269)	47.96 (9241/19269)	37.99 (7321/19269)	31.02 (5977/19269)	27.17 (5235/19269)	24.43 (4707/19269)	21.98 (4236/19269)	20.01 (3856/19269)
	79.48 (14309/18004)	78.93 (12354/15651)	80.73 (10843/13431)	81.84 (8892/10865)	83.61 (7222/8638)	84.02 (5126/6101)	83.87 (3687/4396)	84.25 (2895/3436)	84.79 (2336/2755)	85.22 (1840/2159)	86.77 (1423/1640)
	85.40 (14309/16755)	73.73 (12354/16755)	64.72 (10843/16755)	53.07 (8892/16755)	43.10 (7222/16755)	30.59 (5126/16755)	22.01 (3687/16755)	17.28 (2895/16755)	13.94 (2336/16755)	10.98 (1840/16755)	8.49 (1423/16755)
	82.33 	76.25 	71.84 	64.39 	56.88 	44.85 	34.86 	28.68 	23.95 	19.46 	15.47 
TEST:	60.80 (1208/1987)	59.69 (1186/1987)	56.72 (1127/1987)	53.60 (1065/1987)	50.98 (1013/1987)	45.24 (899/1987)	40.46 (804/1987)	38.50 (765/1987)	37.19 (739/1987)	35.68 (709/1987)	35.08 (697/1987)
	60.15 (1096/1822)	62.40 (976/1564)	63.80 (846/1326)	66.51 (691/1039)	70.36 (572/813)	70.22 (415/591)	68.93 (295/428)	69.25 (232/335)	70.29 (194/276)	68.89 (155/225)	72.73 (128/176)
	79.48 (1096/1379)	70.78 (976/1379)	61.35 (846/1379)	50.11 (691/1379)	41.48 (572/1379)	30.09 (415/1379)	21.39 (295/1379)	16.82 (232/1379)	14.07 (194/1379)	11.24 (155/1379)	9.28 (128/1379)
	68.48 	66.33 	62.55 	57.15 	52.19 	42.13 	32.65 	27.07 	23.44 	19.33 	16.46 
INFO:	2014-08-14_18-03-25	ml_framework.self_training:8a6b7bae81	self-training delible=1 diff_loss=-4
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	78.62 (15150/19269)	70.30 (13547/19269)	61.80 (11908/19269)	52.24 (10067/19269)	41.77 (8048/19269)	32.63 (6288/19269)	26.83 (5169/19269)	23.54 (4535/19269)	20.24 (3900/19269)	17.49 (3371/19269)	15.26 (2940/19269)
	79.48 (14309/18004)	78.61 (12225/15552)	81.08 (10218/12603)	82.88 (8152/9836)	84.60 (5909/6985)	85.63 (4016/4690)	86.77 (2820/3250)	88.18 (2142/2429)	89.66 (1465/1634)	90.26 (908/1006)	92.46 (454/491)
	85.40 (14309/16755)	72.96 (12225/16755)	60.98 (10218/16755)	48.65 (8152/16755)	35.27 (5909/16755)	23.97 (4016/16755)	16.83 (2820/16755)	12.78 (2142/16755)	8.74 (1465/16755)	5.42 (908/16755)	2.71 (454/16755)
	82.33 	75.68 	69.61 	61.31 	49.78 	37.45 	28.19 	22.33 	15.93 	10.22 	5.26 
TEST:	60.80 (1208/1987)	58.93 (1171/1987)	56.11 (1115/1987)	52.64 (1046/1987)	47.16 (937/1987)	41.72 (829/1987)	38.30 (761/1987)	36.74 (730/1987)	35.38 (703/1987)	33.47 (665/1987)	32.11 (638/1987)
	60.15 (1096/1822)	61.99 (959/1547)	65.11 (793/1218)	69.02 (635/920)	70.53 (469/665)	71.33 (321/450)	71.43 (225/315)	72.73 (176/242)	74.72 (133/178)	73.87 (82/111)	78.85 (41/52)
	79.48 (1096/1379)	69.54 (959/1379)	57.51 (793/1379)	46.05 (635/1379)	34.01 (469/1379)	23.28 (321/1379)	16.32 (225/1379)	12.76 (176/1379)	9.64 (133/1379)	5.95 (82/1379)	2.97 (41/1379)
	68.48 	65.55 	61.07 	55.24 	45.89 	35.10 	26.56 	21.71 	17.08 	11.01 	5.73 
INFO:	2014-08-14_18-03-35	ml_framework.self_training:8a6b7bae81	self-training delible=1 diff_loss=-5
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	78.62 (15150/19269)	65.99 (12716/19269)	53.67 (10342/19269)	40.34 (7774/19269)	30.14 (5807/19269)	22.50 (4336/19269)	18.70 (3604/19269)	15.09 (2908/19269)	13.21 (2546/19269)	13.05 (2514/19269)	13.05 (2514/19269)
	79.48 (14309/18004)	79.21 (11181/14116)	82.44 (8455/10256)	84.44 (5643/6683)	88.40 (3476/3932)	89.28 (1933/2165)	91.13 (1151/1263)	92.12 (421/457)	90.00 (36/40)	0.00 (0/0)	0.00 (0/0)
	85.40 (14309/16755)	66.73 (11181/16755)	50.46 (8455/16755)	33.68 (5643/16755)	20.75 (3476/16755)	11.54 (1933/16755)	6.87 (1151/16755)	2.51 (421/16755)	0.21 (36/16755)	0.00 (0/16755)	0.00 (0/16755)
	82.33 	72.44 	62.60 	48.15 	33.61 	20.43 	12.78 	4.89 	0.43 	0.00 	0.00 
TEST:	60.80 (1208/1987)	57.78 (1148/1987)	53.04 (1054/1987)	46.30 (920/1987)	40.16 (798/1987)	36.49 (725/1987)	34.47 (685/1987)	31.76 (631/1987)	30.65 (609/1987)	30.60 (608/1987)	30.60 (608/1987)
	60.15 (1096/1822)	63.00 (877/1392)	67.89 (668/984)	71.18 (447/628)	74.04 (271/366)	75.58 (164/217)	79.07 (102/129)	72.00 (36/50)	60.00 (3/5)	0.00 (0/0)	0.00 (0/0)
	79.48 (1096/1379)	63.60 (877/1379)	48.44 (668/1379)	32.41 (447/1379)	19.65 (271/1379)	11.89 (164/1379)	7.40 (102/1379)	2.61 (36/1379)	0.22 (3/1379)	0.00 (0/1379)	0.00 (0/1379)
	68.48 	63.30 	56.54 	44.54 	31.06 	20.55 	13.53 	5.04 	0.43 	0.00 	0.00 
INFO:	2014-08-14_18-03-45	ml_framework.self_training:8a6b7bae81	self-training delible=1 diff_loss=-6
ML_METHOD:	 vw.ranking mc --loss_function logistic --passes 30
ITER	000	001	002	003	004	005	006	007	008	009	010
TRAIN:	78.62 (15150/19269)	60.34 (11626/19269)	44.00 (8478/19269)	30.81 (5936/19269)	22.24 (4285/19269)	17.09 (3294/19269)	13.98 (2694/19269)	13.05 (2514/19269)	13.05 (2514/19269)	13.05 (2514/19269)	13.05 (2514/19269)
	79.48 (14309/18004)	78.05 (9976/12781)	82.39 (6417/7789)	86.39 (3642/4216)	89.37 (1874/2097)	92.48 (824/891)	93.24 (193/207)	0.00 (0/0)	0.00 (0/0)	0.00 (0/0)	0.00 (0/0)
	85.40 (14309/16755)	59.54 (9976/16755)	38.30 (6417/16755)	21.74 (3642/16755)	11.18 (1874/16755)	4.92 (824/16755)	1.15 (193/16755)	0.00 (0/16755)	0.00 (0/16755)	0.00 (0/16755)	0.00 (0/16755)
	82.33 	67.55 	52.29 	34.73 	19.88 	9.34 	2.28 	0.00 	0.00 	0.00 	0.00 
TEST:	60.80 (1208/1987)	53.95 (1072/1987)	47.66 (947/1987)	41.07 (816/1987)	36.24 (720/1987)	33.22 (660/1987)	31.25 (621/1987)	30.60 (608/1987)	30.60 (608/1987)	30.60 (608/1987)	30.60 (608/1987)
	60.15 (1096/1822)	61.84 (781/1263)	68.29 (504/738)	73.50 (294/400)	76.47 (156/204)	79.31 (69/87)	84.21 (16/19)	0.00 (0/0)	0.00 (0/0)	0.00 (0/0)	0.00 (0/0)
	79.48 (1096/1379)	56.64 (781/1379)	36.55 (504/1379)	21.32 (294/1379)	11.31 (156/1379)	5.00 (69/1379)	1.16 (16/1379)	0.00 (0/1379)	0.00 (0/1379)	0.00 (0/1379)	0.00 (0/1379)
	68.48 	59.12 	47.61 	33.05 	19.71 	9.41 	2.29 	0.00 	0.00 	0.00 	0.00 
